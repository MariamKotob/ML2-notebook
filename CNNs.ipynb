{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2_d4_2_CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariamKotob/ML2-notebook/blob/master/CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9dW4uSU0wIO",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLJ2aAvP0v50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -q install pydot_ng > /dev/null 2>&1\n",
        "!pip -q install graphviz > /dev/null 2>&1\n",
        "!apt install graphviz > /dev/null 2>&1\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KqNXqNlz8qm",
        "colab_type": "text"
      },
      "source": [
        "### 2D Convolution\n",
        "\n",
        "create a function conv2d that performs a 2D Convolution on an input grayscale image (2D numpy array) with a given 2D kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eug2ul4WzyZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e01a6000-1e72-49d3-e1b7-8299a9d2e062"
      },
      "source": [
        "rand_img = np.random.uniform(size=[8, 8])\n",
        "rand_kernel = np.random.uniform(size=[3, 3])\n",
        "plt.imshow(rand_img, cmap='gray')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff791809cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMKElEQVR4nO3da4hc9R3G8ecxJtsabYxNWsSEeokIRaiXJVAs1Sqt2nip0BcqBtRCIBAvtBCt+EbxtdYXXgjxBrVKG10VtRdBS6smmouxbRKtaWjXDbUx0SQmYEKyv77YSdl2k+yZ2XP+M/n1+4HF3Znh/J7BfXJmzp45f0eEAORxVLcDAKgXpQaSodRAMpQaSIZSA8kc3cRGp06dGtOnT29i02Ps37+/yBxJmjFjRrFZkjRlypRiszZu3Fhs1pw5c4rNGhoaKjZLkrZt21ZkzvDwsIaHh32w+xop9fTp03XzzTc3sekxdu7cWWSOJF1//fXFZknS7Nmzi8266qqris16/vnni8267bbbis2SpMcff7zInMP93vPyG0iGUgPJUGogGUoNJEOpgWQoNZAMpQaSodRAMpQaSKZSqW1fYvt92xtt3950KACdG7fUtidJekDSpZK+Luka219vOhiAzlTZU8+VtDEiNkXEXklPS7qy2VgAOlWl1CdJ+nDUz0Ot2/6L7QW2V9letXv37rryAWhTbQfKImJJRPRHRP/UqVPr2iyANlUp9WZJoz8DOKt1G4AeVKXUKyWdbvsU21MkXS3phWZjAejUuBdJiIh9thdJ+q2kSZIejYh1jScD0JFKVz6JiJclvdxwFgA14IwyIBlKDSRDqYFkKDWQDKUGkqHUQDKUGkimkRU6tm/froGBgSY2Pcabb75ZZI4kvf3228VmSdInn3xSbNbFF19cbNZRR5XblwwODhabJUn9/f1F5qxYseKQ97GnBpKh1EAylBpIhlIDyVBqIBlKDSRDqYFkKDWQDKUGkqHUQDJVVuh41PYW238pEQjAxFTZUz8u6ZKGcwCoybiljog/SCr3yQIAE1Lbp7RsL5C0QJKmTJlS12YBtKmRZXcmT55c12YBtImj30AylBpIpsqftJ6StFzSGbaHbP+o+VgAOlVlLa1rSgQBUA9efgPJUGogGUoNJEOpgWQoNZAMpQaSodRAMo0su3Paaafpueeea2LTYzzwwANF5kjSs88+W2yWJN19993FZs2cObPYrA8++KDYrFK/hweUWirp/PPPP+R97KmBZCg1kAylBpKh1EAylBpIhlIDyVBqIBlKDSRDqYFkKDWQTJVrlM22/Zrt9bbX2b6lRDAAnaly7vc+ST+JiDW2j5O02vYrEbG+4WwAOlBl2Z1/RsSa1vefSdog6aSmgwHoTFvvqW2fLOlsSW8d5L4FtlfZXlXqkyoAxqpcatvHSnpG0q0RsfN/7x+97M4JJ5xQZ0YAbahUatuTNVLoJyOi7IeKAbSlytFvS3pE0oaIuLf5SAAmosqe+jxJ8yVdaHtt6+v7DecC0KEqy+68LskFsgCoAWeUAclQaiAZSg0kQ6mBZCg1kAylBpKh1EAylBpIppG1tAYHB7Vw4cImNj3GwMBAkTlS+bW05s2bV2zWG2+8UWzWSy+9VGzW559/XmyWJG3durXInOHh4UPex54aSIZSA8lQaiAZSg0kQ6mBZCg1kAylBpKh1EAylBpIpsqFB79g+23b77aW3bmrRDAAnalymugeSRdGxK7WpYJft/3riFjRcDYAHahy4cGQtKv14+TWVzQZCkDnql7Mf5LttZK2SHolIg677M6ePXvqzgmgokqljoj9EXGWpFmS5to+8yCP+c+yO319fXXnBFBRW0e/I2K7pNckXdJMHAATVeXo90zbx7e+/6Kk70p6r+lgADpT5ej3iZKesD1JI/8I/DIiXmw2FoBOVTn6/SeNrEkN4AjAGWVAMpQaSIZSA8lQaiAZSg0kQ6mBZCg1kAylBpJpZNmdGTNm6MYbb2xi02OsW7euyBxJsl1sliTNnz+/2Ky77ip37YvLL7+82Kxrr7222CxJuueee4rM2b9//yHvY08NJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiAZSg0kQ6mBZCqXunVB/3dsc9FBoIe1s6e+RdKGpoIAqEfVZXdmSZonaWmzcQBMVNU99c8kLZY0fKgHjF5La8eOHbWEA9C+Kit0XCZpS0SsPtzjRq+lNW3atNoCAmhPlT31eZKusP13SU9LutD2zxtNBaBj45Y6In4aEbMi4mRJV0t6NSKuazwZgI7wd2ogmbYuZxQRv5f0+0aSAKgFe2ogGUoNJEOpgWQoNZAMpQaSodRAMpQaSKaRZXcGBwe1aNGiJjY9xplnnllkjiSde+65xWZJ0q5du4rN2rRpU7FZd9xxR7FZQ0NDxWZJ0vLly4vMYdkd4P8IpQaSodRAMpQaSIZSA8lQaiAZSg0kQ6mBZCg1kAylBpKpdJpo60qin0naL2lfRPQ3GQpA59o59/s7EbG1sSQAasHLbyCZqqUOSb+zvdr2goM9YPSyO4f7BAmAZlV9+f2tiNhs+yuSXrH9XkT8YfQDImKJpCWS1NfXFzXnBFBRpT11RGxu/XeLpAFJc5sMBaBzVRbIm2r7uAPfS/qepL80HQxAZ6q8/P6qpAHbBx7/i4j4TaOpAHRs3FJHxCZJ3yiQBUAN+JMWkAylBpKh1EAylBpIhlIDyVBqIBlKDSTTyLI7+/bt07Zt25rY9BiLFy8uMkeS5s4te3bsypUri8264IILis369NNPi81atmxZsVmSdP/99xeZc7jlhNhTA8lQaiAZSg0kQ6mBZCg1kAylBpKh1EAylBpIhlIDyVBqIJlKpbZ9vO1ltt+zvcH2N5sOBqAzVc/9vl/SbyLih7anSDqmwUwAJmDcUtueJunbkq6XpIjYK2lvs7EAdKrKy+9TJH0s6THb79he2rr+938ZvexOBAt0AN1SpdRHSzpH0kMRcbak3ZJu/98HRcSSiOiPiP7WNcIBdEGVUg9JGoqIt1o/L9NIyQH0oHFLHREfSfrQ9hmtmy6StL7RVAA6VvXo902Snmwd+d4k6YbmIgGYiEqljoi1kvobzgKgBpxRBiRDqYFkKDWQDKUGkqHUQDKUGkiGUgPJUGogmUbW0jr11FN13333NbHpMR5++OEicyTpwQcfLDZLOvx6SXWbM2dOsVnvvvtusVl9fX3FZknSwoULi8y58847D3kfe2ogGUoNJEOpgWQoNZAMpQaSodRAMpQaSIZSA8lQaiCZcUtt+wzba0d97bR9a4lwANo37mmiEfG+pLMkyfYkSZslDTScC0CH2n35fZGkv0XEP5oIA2Di2i311ZKeOtgdo5fd2bFjx8STAehI5VK3rvl9haRfHez+0cvuTJs2ra58ANrUzp76UklrIuJfTYUBMHHtlPoaHeKlN4DeUanUraVrvyvp2WbjAJioqsvu7Jb05YazAKgBZ5QByVBqIBlKDSRDqYFkKDWQDKUGkqHUQDKUGkjGEVH/Ru2PJbX78cwZkrbWHqY3ZH1uPK/u+VpEzDzYHY2UuhO2V0VEf7dzNCHrc+N59SZefgPJUGogmV4q9ZJuB2hQ1ufG8+pBPfOeGkA9emlPDaAGlBpIpidKbfsS2+/b3mj79m7nqYPt2bZfs73e9jrbt3Q7U51sT7L9ju0Xu52lTraPt73M9nu2N9j+Zrcztavr76lbCwT8VSOXSxqStFLSNRGxvqvBJsj2iZJOjIg1to+TtFrSD47053WA7R9L6pf0pYi4rNt56mL7CUl/jIilrSvoHhMR27udqx29sKeeK2ljRGyKiL2SnpZ0ZZczTVhE/DMi1rS+/0zSBkkndTdVPWzPkjRP0tJuZ6mT7WmSvi3pEUmKiL1HWqGl3ij1SZI+HPXzkJL88h9g+2RJZ0t6q7tJavMzSYslDXc7SM1OkfSxpMdaby2Wti66eUTphVKnZvtYSc9IujUidnY7z0TZvkzSlohY3e0sDTha0jmSHoqIsyXtlnTEHePphVJvljR71M+zWrcd8WxP1kihn4yILJdXPk/SFbb/rpG3Shfa/nl3I9VmSNJQRBx4RbVMIyU/ovRCqVdKOt32Ka0DE1dLeqHLmSbMtjXy3mxDRNzb7Tx1iYifRsSsiDhZI/+vXo2I67ocqxYR8ZGkD22f0brpIklH3IHNStf9blJE7LO9SNJvJU2S9GhErOtyrDqcJ2m+pD/bXtu67Y6IeLmLmTC+myQ92drBbJJ0Q5fztK3rf9ICUK9eePkNoEaUGkiGUgPJUGogGUoNJEOpgWQoNZDMvwGWe/rckzEpqwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmBq-NIn0-eG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(img, kernel):\n",
        "    #Your code goes here\n",
        "    out_img = np.zeros([ (img.shape[0]-kernel.shape[0]+1), (img.shape[1]-kernel.shape[1]+1) ])\n",
        "    for i in range(out_img.shape[0]):\n",
        "      for j in range(out_img.shape[1]):\n",
        "        out_img[i, j] = np.sum( np.multiply( kernel, img[i:i+kernel.shape[0], j:j+kernel.shape[1]]))\n",
        "    return out_img"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzQ2Wqdr3213",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "87cae087-1c1e-4db7-e717-f1b6f3bdb1e7"
      },
      "source": [
        "convoluted_img = conv2d(rand_img, rand_kernel)\n",
        "plt.imshow(convoluted_img, cmap='gray')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff78a1a9518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXqyqAvYANk_",
        "colab_type": "text"
      },
      "source": [
        "Now add the padding and stride:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTC7cQ4t4G8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(img, kernel, padding=0, stride=1):\n",
        "    #Your code goes here\n",
        "    out_img = np.zeros([ \n",
        "                        (img.shape[0]-kernel.shape[0]+1+2*padding) // stride, \n",
        "                        (img.shape[1]-kernel.shape[1]+1+2*padding) // stride \n",
        "                        ])\n",
        "    #padded_img = np.zeros([ (img.shape[0]+2*padding), (img.shape[1]+2*padding) ])\n",
        "    #padded_img[padding:-padding , padding:-padding] = rand_img\n",
        "    padded_img = np.pad(img, padding, 'constant')\n",
        "    k, l = 0, 0\n",
        "    for i in range(out_img.shape[0]):\n",
        "      for j in range(out_img.shape[1]):\n",
        "        out_img[i, j] = np.sum( np.multiply( kernel, padded_img[k:k+kernel.shape[0], l:l+kernel.shape[1]]))\n",
        "        l += stride \n",
        "      k += stride\n",
        "      l = 0\n",
        "    return out_img"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUkqCIUf6S5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "bdd92c32-2742-44f7-d8fa-8163f50a1432"
      },
      "source": [
        "convoluted_img = conv2d(rand_img, rand_kernel, padding=0, stride=2)\n",
        "plt.imshow(convoluted_img, cmap='gray')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff789ca3668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZWFtjJWEJe5",
        "colab_type": "text"
      },
      "source": [
        "Now adjust the hyperparameters using the sliders on the right and see how the output shape changes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1K9fCaHA-fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "292aa02d-f3cd-4457-c0e1-e42d6c23f14d"
      },
      "source": [
        "#@title Convolutional layer parameters {run: \"auto\"}\n",
        "filters = 0  #@param { type: \"slider\", min:0, max: 10, step: 1 }\n",
        "kernel_size = 3 #@param { type: \"slider\", min:1, max: 10, step: 1 }\n",
        "stride = 2 #@param { type: \"slider\", min:1, max: 3, step: 1 }\n",
        "\n",
        "# Create a random colour \"image\" of shape 10x10 with a depth of 3 (for red, green and blue)\n",
        "dummy_input = np.random.uniform(size=[10, 10, 3])\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "plt.imshow(dummy_input)\n",
        "ax.grid(False)\n",
        "print('Input shape: {}'.format(dummy_input.shape))\n",
        "\n",
        "conv_layer = tf.keras.layers.Conv2D(\n",
        "    filters=filters,\n",
        "    kernel_size=kernel_size,\n",
        "    strides=stride,\n",
        "    padding=\"valid\",\n",
        "    input_shape=[10, 10, 3])\n",
        "\n",
        "# Convert the image to a tensor and add an extra batch dimension which\n",
        "# the convolutional layer expects.\n",
        "input_tensor = tf.convert_to_tensor(dummy_input[None, :, :, :])\n",
        "convoluted = conv_layer(input_tensor)\n",
        "\n",
        "print('The output dimension is: {}'.format(list(convoluted.shape)[1:]))\n",
        "print('The number of parameters is: {}'.format(conv_layer.count_params()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (10, 10, 3)\n",
            "WARNING:tensorflow:Layer conv2d_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "The output dimension is: [4, 4, 1]\n",
            "The number of parameters is: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euqqnI28FRSF",
        "colab_type": "text"
      },
      "source": [
        "### Pooling\n",
        "\n",
        "Create a function called max_pool that performs a max pooling operation on a given image with a given kernel size and a given stride"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_3bCix-Ew0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool(image, kernel_size=2, stride=2):\n",
        "    #Your code goes here\n",
        "    out_img = np.zeros([ \n",
        "                        1+ (image.shape[0]-kernel_size) // stride, \n",
        "                        1+ (image.shape[1]-kernel_size) // stride \n",
        "                        ])\n",
        "    k, l = 0, 0\n",
        "    for i in range(out_img.shape[0]):\n",
        "      for j in range(out_img.shape[1]):\n",
        "        out_img[i, j] = np.max( image[k:k+kernel_size, l:l+kernel_size])\n",
        "        l += stride \n",
        "      k += stride\n",
        "      l = 0\n",
        "    return out_img"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayD0K8iEF5Wh",
        "colab_type": "text"
      },
      "source": [
        "Now compare the results with the MaxPooling2D from tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in1WGIIwF50e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8c7b0ead-dd4e-473c-9f23-d98018a1e0b7"
      },
      "source": [
        "X = np.array([[9, 5, 4, 5, 6, 4],\n",
        "              [6, 6, 3, 5, 8, 2],\n",
        "              [4, 6, 9, 1, 3, 6],\n",
        "              [9, 7, 1, 5, 8, 1],\n",
        "              [4, 9, 9, 5, 7, 3],\n",
        "              [7, 3, 6, 4, 9, 1]])\n",
        "\n",
        "print(max_pool(X, kernel_size=2, stride=2))\n",
        "\n",
        "max_pool_layer = tf.keras.layers.MaxPooling2D((2, 2), strides=2)\n",
        "max_pool_layer(tf.convert_to_tensor(X[None, :, :, None])).numpy().squeeze()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9. 5. 8.]\n",
            " [9. 9. 8.]\n",
            " [9. 9. 9.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9, 5, 8],\n",
              "       [9, 9, 8],\n",
              "       [9, 9, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99NejbrGer9",
        "colab_type": "text"
      },
      "source": [
        "### Custom keras Layers\n",
        "\n",
        "With tf.keras we can create custom layers using the subclassing of tf.keras.layes.Layer. For example, to build a custom dense layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKhhzB3bF8K9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_outputs):\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "    self.num_outputs = num_outputs\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.kernel = self.add_weight(\"kernel\",\n",
        "                                  shape = [int(input_shape[-1]), \n",
        "                                           self.num_outputs])\n",
        "  \n",
        "  def call(self, input):\n",
        "    return tf.matmul(input, self.kernel)\n",
        "\n",
        "layer = MyDenseLayer(10)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cZijwZvIKU9",
        "colab_type": "text"
      },
      "source": [
        "Now create a ResNet block using the subclassing method\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYk2Pg-MIP2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetBlock(tf.keras.Model):\n",
        "  def __init__(self, kernel_size, filters):\n",
        "    super(ResNetBlock, self).__init__(name='')\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size)\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size)\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training = False):\n",
        "    x = self.conv1(input_tensor)\n",
        "    x = self.bn1(x)\n",
        "    x = tf.nn.relu(x) \n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x += input_tensor \n",
        "    return tf.nn.relu(x)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEgzXAp69kR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "13f64c14-e501-473d-cb8d-e0ed12f9266f"
      },
      "source": [
        "block = ResNetBlock(1, 3)\n",
        "_ = block(tf.zeros([1, 3, 3, 3]))\n",
        "block.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net_block_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            multiple                  12        \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch multiple                  12        \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            multiple                  12        \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch multiple                  12        \n",
            "=================================================================\n",
            "Total params: 48\n",
            "Trainable params: 36\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FACcajEJLZ8U",
        "colab_type": "text"
      },
      "source": [
        "### How to build models with tf.keras\n",
        "\n",
        "1. Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnjXTWeVIfwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.Conv2D(1, (1,1), input_shape=(None, None, 3)),\n",
        "                                tf.keras.layers.BatchNormalization(),\n",
        "                                tf.keras.layers.Conv2D(1, (1,1)),\n",
        "                                ResNetBlock(1, 3)\n",
        "                                ])\n",
        "for i in range(2):\n",
        "  my_model.add(ResNetBlock(1, 3))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVr3eCX_AJuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "10677f4e-18b0-4c69-b24b-52fbc6b44b06"
      },
      "source": [
        "my_model(tf.zeros([1, 2, 3, 3]))\n",
        "my_model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, None, None, 1)     4         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, None, None, 1)     4         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, None, None, 1)     2         \n",
            "_________________________________________________________________\n",
            "res_net_block_4 (ResNetBlock (None, None, None, 3)     42        \n",
            "_________________________________________________________________\n",
            "res_net_block_5 (ResNetBlock (None, None, None, 3)     48        \n",
            "_________________________________________________________________\n",
            "res_net_block_6 (ResNetBlock (None, None, None, 3)     48        \n",
            "=================================================================\n",
            "Total params: 148\n",
            "Trainable params: 110\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3uao-ZRLmsB",
        "colab_type": "text"
      },
      "source": [
        "2. Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-GnE-KB2B3ka",
        "colab": {}
      },
      "source": [
        "def minigooglenet_functional(width, height, depth, classes):\n",
        "\tdef conv_module(x, K, kX, kY, stride, chanDim, padding=\"same\"):\n",
        "\t\t# define a CONV => BN => RELU pattern\n",
        "\t\tx = Conv2D(K, (kX, kY), strides=stride, padding=padding)(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef inception_module(x, numK1x1, numK3x3, chanDim):\n",
        "\t\t# define two CONV modules, then concatenate across the\n",
        "\t\t# channel dimension\n",
        "\t\tconv_1x1 = conv_module(x, numK1x1, 1, 1, (1, 1), chanDim)\n",
        "\t\tconv_3x3 = conv_module(x, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "\t\tx = concatenate([conv_1x1, conv_3x3], axis=chanDim)\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\n",
        "\tdef downsample_module(x, K, chanDim):\n",
        "\t\t# define the CONV module and POOL, then concatenate\n",
        "\t\t# across the channel dimensions\n",
        "\t\tconv_3x3 = conv_module(x, K, 3, 3, (2, 2), chanDim,\n",
        "\t\t\tpadding=\"valid\")\n",
        "\t\tpool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\t\tx = concatenate([conv_3x3, pool], axis=chanDim)\n",
        "\t\t# return the block\n",
        "\t\treturn x\n",
        "\t\n",
        "\t# initialize the input shape to be \"channels last\" and the\n",
        "\t# channels dimension itself\n",
        "\tinputShape = (height, width, depth)\n",
        "\tchanDim = -1\n",
        "\t# define the model input and first CONV module\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = conv_module(inputs, 96, 3, 3, (1, 1), chanDim)\n",
        "\t# two Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 32, 32, chanDim)\n",
        "\tx = inception_module(x, 32, 48, chanDim)\n",
        "\tx = downsample_module(x, 80, chanDim)\n",
        "\t# four Inception modules followed by a downsample module\n",
        "\tx = inception_module(x, 112, 48, chanDim)\n",
        "\tx = inception_module(x, 96, 64, chanDim)\n",
        "\tx = inception_module(x, 80, 80, chanDim)\n",
        "\tx = inception_module(x, 48, 96, chanDim)\n",
        "\tx = downsample_module(x, 96, chanDim)\n",
        "\t# two Inception modules followed by global POOL and dropout\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = inception_module(x, 176, 160, chanDim)\n",
        "\tx = AveragePooling2D((7, 7))(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\t# softmax classifier\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(classes)(x)\n",
        "\tx = Activation(\"softmax\")(x)\n",
        "\t# create the model\n",
        "\tmodel = Model(inputs, x, name=\"minigooglenet\")\n",
        "\t# return the constructed network architecture\n",
        "\treturn model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kza5QGVgMp0s",
        "colab_type": "text"
      },
      "source": [
        "3. Model Subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q937C1gJB_Q3",
        "colab": {}
      },
      "source": [
        "class MiniVGGNetModel(tf.keras.Model):\n",
        "\tdef __init__(self, classes, chanDim=-1):\n",
        "\t\t# call the parent constructor\n",
        "\t\tsuper(MiniVGGNetModel, self).__init__()\n",
        "\t\t\n",
        "\t\t# initialize the layers in the first (CONV => RELU) * 2 => POOL\n",
        "\t\t# layer set\n",
        "\t\tself.conv1A = Conv2D(32, (3, 3), padding=\"same\")\n",
        "\t\tself.act1A = Activation(\"relu\")\n",
        "\t\tself.bn1A = BatchNormalization(axis=chanDim)\n",
        "\t\tself.conv1B = Conv2D(32, (3, 3), padding=\"same\")\n",
        "\t\tself.act1B = Activation(\"relu\")\n",
        "\t\tself.bn1B = BatchNormalization(axis=chanDim)\n",
        "\t\tself.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
        "\t\t\n",
        "\t\t# initialize the layers in the second (CONV => RELU) * 2 => POOL\n",
        "\t\t# layer set\n",
        "\t\tself.conv2A = Conv2D(32, (3, 3), padding=\"same\")\n",
        "\t\tself.act2A = Activation(\"relu\")\n",
        "\t\tself.bn2A = BatchNormalization(axis=chanDim)\n",
        "\t\tself.conv2B = Conv2D(32, (3, 3), padding=\"same\")\n",
        "\t\tself.act2B = Activation(\"relu\")\n",
        "\t\tself.bn2B = BatchNormalization(axis=chanDim)\n",
        "\t\tself.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
        "\t\t\n",
        "\t\t# initialize the layers in our fully-connected layer set\n",
        "\t\tself.flatten = Flatten()\n",
        "\t\tself.dense3 = Dense(512)\n",
        "\t\tself.act3 = Activation(\"relu\")\n",
        "\t\tself.bn3 = BatchNormalization()\n",
        "\t\tself.do3 = Dropout(0.5)\n",
        "\t\t\n",
        "\t\t# initialize the layers in the softmax classifier layer set\n",
        "\t\tself.dense4 = Dense(classes)\n",
        "\t\tself.softmax = Activation(\"softmax\")\n",
        "  \n",
        "\t\n",
        "\t\n",
        "\tdef call(self, inputs):\n",
        "\t\t# build the first (CONV => RELU) * 2 => POOL layer set\n",
        "\t\tx = self.conv1A(inputs)\n",
        "\t\tx = self.act1A(x)\n",
        "\t\tx = self.bn1A(x)\n",
        "\t\tx = self.conv1B(x)\n",
        "\t\tx = self.act1B(x)\n",
        "\t\tx = self.bn1B(x)\n",
        "\t\tx = self.pool1(x)\n",
        "\t\t\n",
        "\t\t# build the second (CONV => RELU) * 2 => POOL layer set\n",
        "\t\tx = self.conv2A(x)\n",
        "\t\tx = self.act2A(x)\n",
        "\t\tx = self.bn2A(x)\n",
        "\t\tx = self.conv2B(x)\n",
        "\t\tx = self.act2B(x)\n",
        "\t\tx = self.bn2B(x)\n",
        "\t\tx = self.pool2(x)\n",
        "\t\t\n",
        "\t\t# build our FC layer set\n",
        "\t\tx = self.flatten(x)\n",
        "\t\tx = self.dense3(x)\n",
        "\t\tx = self.act3(x)\n",
        "\t\tx = self.bn3(x)\n",
        "\t\tx = self.do3(x)\n",
        "\t\t\n",
        "\t\t# build the softmax classifier\n",
        "\t\tx = self.dense4(x)\n",
        "\t\tx = self.softmax(x)\n",
        "\t\t\n",
        "\t\t# return the constructed model\n",
        "\t\treturn x"
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}